{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e219198a-04ba-44df-a5cc-f68905da00fb",
   "metadata": {},
   "source": [
    "## Model Design Rationale (EfficientNetB0)\n",
    "\n",
    "This model was trained on a small ultrasound dataset (<800 images) for 3-way classification: benign, malignant, and normal.\n",
    "\n",
    "### Why EfficientNetB0?\n",
    "Although we initially tested larger backbones like EfficientNetB3, we found that EfficientNetB0 consistently outperformed it on this limited dataset. B0's smaller size makes it less prone to overfitting and easier to optimize. It provides strong performance with fewer parameters, faster training, and greater stabilityâ€”making it a better match for small-scale medical imaging tasks. We briefly tested alternatives like ResNet50 and MobileNetV2, but they didn't perform quite as well. EfficientNetB0 provides a lightweight model, that is very fast and accurate for its size with strong pretrained features.\n",
    "\n",
    "### Why Freeze Most of the Base?\n",
    "While full fine-tuning led to marginal gains, the most stable improvements came from a 2-phase approach: training only the classification head first, then fine-tuning just the final convolutional block (with BatchNorm layers frozen). This balances generalization and overfitting risk on limited data, leveraging EfficientNetB0's pretrained features while still adapting the top layers.\n",
    "\n",
    "### Augmentation Strategy\n",
    "We applied geometric and brightness augmentations (rotation, flips, zoom, etc.) to increase diversity without harming structural integrity. Cutout and mixup were avoided after brief tests showed performance drops. Each epoch applies a random type of augmentation and all images are trained on once per epoch, ensuring that over many epochs the model sees varied versions of each image to enhance generalization without increasing dataset size.\n",
    "\n",
    "### Class Imbalance Handling\n",
    "The dataset had class imbalances, with some classes (e.g., benign) appearing more frequently than others. To correct this, we used `class_weight='balanced'` to adjust for skewed class distributions. This helped prevent the model from overpredicting common classes (e.g., benign)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d9ffa-1536-456c-81eb-4ecd9cb7321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Versions Used:\n",
    "# TensorFlow:         2.1.0\n",
    "# Keras:              1.1.0\n",
    "# Pandas:             1.1.3\n",
    "# Numpy:              1.18.5\n",
    "# Scikit-Learn:       0.22.2\n",
    "# Matplotlib:         3.1.3\n",
    "\n",
    "\"\"\"\n",
    "MRI Classification - EfficientNetB0 (3-class: benign, malignant, normal)\n",
    "\n",
    "This model trains a classifier head on a frozen EfficientNetB0 base.\n",
    "Key strategies:\n",
    "- Uses 5-fold stratified cross-validation\n",
    "- Applies geometric & brightness augmentations\n",
    "- Balances class imbalance with class weights\n",
    "- Avoids fine-tuning the base due to instability on small data\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt # For plotting history\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "# --- Configuration ---\n",
    "data_dir = 'data'\n",
    "all_data_dir = os.path.join(data_dir, 'all')\n",
    "\n",
    "if not os.path.exists(all_data_dir):\n",
    "    raise FileNotFoundError(f\"Combined data directory not found: {all_data_dir}\")\n",
    "\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 16\n",
    "num_classes = 3\n",
    "max_epochs_per_fold = 75 # Keep max epochs high, let early stopping work\n",
    "n_splits = 5\n",
    "\n",
    "# --- 1. Load All Data Information ---\n",
    "print(\"Loading all image file paths and labels...\")\n",
    "filepaths = []\n",
    "labels = []\n",
    "# Use list comprehension for potentially cleaner directory filtering\n",
    "class_names = sorted([d for d in os.listdir(all_data_dir) if os.path.isdir(os.path.join(all_data_dir, d))])\n",
    "if len(class_names) != num_classes:\n",
    "    print(f\"Warning: Found {len(class_names)} directories/classes, expected {num_classes}. Adjusting.\")\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "class_map = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(all_data_dir, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for fname in os.listdir(class_dir):\n",
    "            fpath = os.path.join(class_dir, fname)\n",
    "            # Basic check for image files\n",
    "            if os.path.isfile(fpath) and fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                filepaths.append(os.path.normpath(fpath))\n",
    "                labels.append(class_name)\n",
    "\n",
    "all_data_df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "all_data_df.dropna(subset=['filepath'], inplace=True) # Ensure no missing paths\n",
    "\n",
    "print(f\"Loaded {len(all_data_df)} valid image paths.\")\n",
    "if len(all_data_df) == 0:\n",
    "     raise ValueError(\"No valid image files found. Check 'all_data_dir' and image file extensions.\")\n",
    "print(\"Class distribution in full dataset:\")\n",
    "print(all_data_df['label'].value_counts())\n",
    "\n",
    "# --- 2. Data Augmentation Generators ---\n",
    "# Back to geometric + brightness augmentation (NO Cutout)\n",
    "print(\"Setting up Data Generators (Geometric + Brightness)...\")\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    "    # No preprocessing_function needed now\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# --- 3. K-Fold Cross-Validation Setup ---\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "# --- Function to build the model (SIMPLIFIED HEAD) ---\n",
    "def build_model(input_shape, num_classes):\n",
    "    print(\"Building fresh model instance with SIMPLIFIED head...\")\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False # Keep frozen\n",
    "\n",
    "    # *** Simplified Head ***\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.5)(x) # Single dropout after GAP\n",
    "    predictions = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    # Removed intermediate Dense(256) and second Dropout\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Keep LR and optimizer same as previous successful run\n",
    "    initial_learning_rate = 3e-4\n",
    "    optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    print(\"Model compiled.\")\n",
    "    return model\n",
    "\n",
    "# --- 4. K-Fold Training Loop ---\n",
    "print(f\"\\n--- Starting {n_splits}-Fold Cross-Validation with Simplified Head ---\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(all_data_df['filepath'], all_data_df['label'])):\n",
    "    print(f\"\\n===== FOLD {fold+1}/{n_splits} =====\")\n",
    "\n",
    "    train_df = all_data_df.iloc[train_idx]\n",
    "    val_df = all_data_df.iloc[val_idx]\n",
    "    print(f\"Fold {fold+1}: Train size={len(train_df)}, Val size={len(val_df)}\")\n",
    "\n",
    "    train_labels_int = train_df['label'].map(class_map).values\n",
    "    unique_train_labels = np.unique(train_labels_int)\n",
    "    try:\n",
    "        fold_class_weights_array = compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=unique_train_labels,\n",
    "            y=train_labels_int\n",
    "        )\n",
    "        fold_class_weights = {label_int: 0.0 for label_int in range(num_classes)}\n",
    "        for label_int, weight in zip(unique_train_labels, fold_class_weights_array):\n",
    "            fold_class_weights[label_int] = weight\n",
    "        if any(w == 0.0 for w in fold_class_weights.values()) and len(unique_train_labels) < num_classes:\n",
    "             print(f\"Warning: Fold {fold+1} training set missing some classes. Weights: {fold_class_weights}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Warning: Could not compute class weights for Fold {fold+1}. Error: {e}. Setting weights to None.\")\n",
    "        fold_class_weights = None\n",
    "\n",
    "    print(f\"Fold {fold+1} Class Weights: {fold_class_weights}\")\n",
    "\n",
    "    fold_train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        classes=class_names,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    fold_val_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        classes=class_names,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    model = build_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "    # Callbacks (same as previous successful run)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, verbose=1, min_lr=1e-7)\n",
    "    callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "    print(f\"--- Training Fold {fold+1} ---\")\n",
    "    history = model.fit(\n",
    "        fold_train_generator,\n",
    "        epochs=max_epochs_per_fold,\n",
    "        validation_data=fold_val_generator,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=fold_class_weights,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"--- Evaluating Fold {fold+1} ---\")\n",
    "    loss, accuracy = model.evaluate(fold_val_generator, verbose=0)\n",
    "    print(f\"Fold {fold+1} Validation Loss: {loss:.4f}\")\n",
    "    print(f\"Fold {fold+1} Validation Accuracy: {accuracy:.4f}\")\n",
    "    fold_results.append(accuracy)\n",
    "\n",
    "    # Clean up memory\n",
    "    del model\n",
    "    del fold_train_generator\n",
    "    del fold_val_generator\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# --- 5. Report Final Cross-Validation Results ---\n",
    "print(\"\\n--- Cross-Validation Results with Simplified Head ---\")\n",
    "mean_accuracy = np.mean(fold_results)\n",
    "std_accuracy = np.std(fold_results)\n",
    "print(f\"Fold Validation Accuracies: {[f'{acc:.4f}' for acc in fold_results]}\")\n",
    "print(f\"Average Validation Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Standard Deviation of Validation Accuracy: {std_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d15c4c-d63a-4642-92f8-d821ce310823",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"efficientnet\"\n",
    "model_path = f\"{MODEL_NAME}.h5\"\n",
    "\n",
    "print(\"\\n--- Training Final Model on ALL Data ---\")\n",
    "\n",
    "# --- Configuration (repeat relevant parts) ---\n",
    "data_dir = 'data'\n",
    "all_data_dir = os.path.join(data_dir, 'all')\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 16\n",
    "num_classes = 3 # Adjust if different\n",
    "# Determine training epochs based on K-Fold results (where val_loss plateaued/stopped)\n",
    "final_epochs = 45 # <<< Adjust this number as needed (e.g., 40-50 seems reasonable)\n",
    "\n",
    "# --- 1. Load All Data Info (same as K-Fold start) ---\n",
    "print(\"Loading all image file paths and labels for final training...\")\n",
    "filepaths = []\n",
    "labels = []\n",
    "class_names = sorted([d for d in os.listdir(all_data_dir) if os.path.isdir(os.path.join(all_data_dir, d))])\n",
    "if len(class_names) != num_classes:\n",
    "    print(f\"Warning: Found {len(class_names)} classes. Adjusting num_classes.\")\n",
    "    num_classes = len(class_names)\n",
    "class_map = {name: i for i, name in enumerate(class_names)}\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(all_data_dir, class_name)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for fname in os.listdir(class_dir):\n",
    "            fpath = os.path.join(class_dir, fname)\n",
    "            if os.path.isfile(fpath) and fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                filepaths.append(os.path.normpath(fpath))\n",
    "                labels.append(class_name)\n",
    "all_data_df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "all_data_df.dropna(subset=['filepath'], inplace=True)\n",
    "print(f\"Loaded {len(all_data_df)} valid image paths for final training.\")\n",
    "if len(all_data_df) == 0:\n",
    "     raise ValueError(\"No valid image files found for final training.\")\n",
    "\n",
    "# --- 2. Data Generator for Final Training (No Cutout) ---\n",
    "print(\"Setting up Data Generator for final training (Geometric + Brightness)...\")\n",
    "final_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    "    # No preprocessing_function\n",
    ")\n",
    "final_train_generator = final_train_datagen.flow_from_dataframe(\n",
    "    dataframe=all_data_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=class_names,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# --- 3. Calculate Class Weights for ALL Data ---\n",
    "print(\"Calculating class weights for the full dataset...\")\n",
    "all_labels_int = all_data_df['label'].map(class_map).values\n",
    "all_class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(list(class_map.values())),\n",
    "    y=all_labels_int\n",
    ")\n",
    "all_class_weights = {label_int: weight for label_int, weight in zip(class_map.values(), all_class_weights_array)}\n",
    "print(f\"Full Dataset Class Weights: {all_class_weights}\")\n",
    "\n",
    "\n",
    "# --- 4. Build and Compile Final Model (Simplified Head) ---\n",
    "# Function to build the specific model configuration\n",
    "def build_final_model(input_shape, num_classes):\n",
    "    print(\"Building final model instance with SIMPLIFIED head...\")\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False # Keep frozen\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dropout(0.5)(x) # Single dropout after GAP\n",
    "    predictions = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model # Return uncompiled model\n",
    "\n",
    "final_model = build_final_model((img_height, img_width, 3), num_classes)\n",
    "\n",
    "# Compile the model\n",
    "initial_learning_rate = 3e-4 # Start with the LR used in K-Fold\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "final_model.compile(optimizer=optimizer,\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "print(\"Final model compiled.\")\n",
    "final_model.summary()\n",
    "\n",
    "# --- 5. Define Callback for Final Training ---\n",
    "reduce_lr_final = ReduceLROnPlateau(\n",
    "    monitor='loss', # Monitor training loss\n",
    "    factor=0.2,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    min_lr=1e-7\n",
    "    )\n",
    "callbacks_final = [reduce_lr_final]\n",
    "\n",
    "# --- 6. Train the Final Model ---\n",
    "print(f\"\\n--- Starting Final Training on ALL Data for {final_epochs} epochs ---\")\n",
    "history_final = final_model.fit(\n",
    "    final_train_generator,\n",
    "    epochs=final_epochs,\n",
    "    callbacks=callbacks_final,\n",
    "    class_weight=all_class_weights,\n",
    "    verbose=1 # Show progress\n",
    ")\n",
    "\n",
    "# --- 7. Save the Final Model ---\n",
    "final_model.save(model_path)\n",
    "print(f\"\\n--- Final Model Saved to {model_path} ---\")\n",
    "\n",
    "# --- 8. Optional: Plot Final Training History ---\n",
    "try:\n",
    "    def plot_final_history(history):\n",
    "        acc = history.history.get('accuracy', [])\n",
    "        loss = history.history.get('loss', [])\n",
    "\n",
    "        if not acc:\n",
    "             print(\"No training history to plot.\")\n",
    "             return\n",
    "\n",
    "        epochs_range = range(len(acc))\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "        plt.title('Final Training Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right'); plt.grid(True)\n",
    "        plt.ylim([min(0.0, min(acc)*0.9), 1.0])\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range, loss, label='Training Loss')\n",
    "        plt.title('Final Training Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper right'); plt.grid(True)\n",
    "        plt.ylim([0, max(loss)*1.1])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\nPlotting final training history...\")\n",
    "    plot_final_history(history_final)\n",
    "except Exception as e:\n",
    "    print(f\"\\nError plotting history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288f717-160e-404f-a9a2-2af723185af5",
   "metadata": {},
   "source": [
    "Example to show the models output on a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfe52f4-4d93-40ca-b9fe-6137aa1737f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"mal_test.png\"\n",
    "img_height, img_width = 300, 300\n",
    "class_names = ['benign', 'malignant', 'normal'] \n",
    "\n",
    "# --- Load Model ---\n",
    "model = load_model(model_path)\n",
    "print(f\"âœ… Loaded model from: {model_path}\")\n",
    "\n",
    "# --- Load and Preprocess Image ---\n",
    "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# --- Predict ---\n",
    "pred_probs = model.predict(img_batch)[0]\n",
    "pred_class_idx = np.argmax(pred_probs)\n",
    "pred_class_name = class_names[pred_class_idx]\n",
    "confidence = pred_probs[pred_class_idx]\n",
    "\n",
    "# --- Display Image & Prediction ---\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(img_array)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Predicted: {pred_class_name} ({confidence*100:.1f}%)\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# --- Display Confidence for All Classes ---\n",
    "plt.figure(figsize=(7, 4))\n",
    "bars = plt.bar(class_names, pred_probs * 100)\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n",
    "             f\"{pred_probs[i]*100:.1f}%\", ha='center', fontsize=12)\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel(\"Confidence (%)\")\n",
    "plt.title(\"Model Confidence per Category\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d194a0c4-d8f5-4588-961d-1242b076924a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflowjs)",
   "language": "python",
   "name": "tensorflowjs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
